\documentclass{beamer}
%\documentclass[handout]{beamer}
% This file is a solution template for:

% - Giving a talk on some subject.
% - The talk is between 15min and 45min long.
% - Style is ornate.

% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 


\mode<presentation>
{
  \usetheme{Montpellier}

  %\setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}

\usepackage{xcolor}
\usepackage{amsmath}

%\input ../macros.tex

\beamerdefaultoverlayspecification{<+->}

% Define a color for mathematical expressions
\definecolor{mathred}{RGB}{200,0,0}
\newcommand{\redmath}[1]{\textcolor{mathred}{#1}}

\usepackage[english]{babel}

\usepackage[latin1]{inputenc}
\usepackage{xcolor}
\usepackage{times}
\usepackage[T1]{fontenc}

% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\title [Specialists] %(optional, use only with long paper titles)
{Predictors that Specialize}

\author[Freund] % (optional, use only with lots of authors)
{Yoav Freund}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[Universities of Somewhere and Elsewhere] % (optional, but mostly needed)

\subject{Machine Learning}
% This is only inserted into the PDF information catalog. Can be left
% out. 

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
%% \AtBeginSubsection[]
%% {
%%   \begin{frame}<beamer>
%%     \frametitle{Outline}
%%     \tableofcontents[currentsection,currentsubsection]
%%   \end{frame}
%% }


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

\beamerdefaultoverlayspecification{<+->}

\input{../macros}

\begin{document}
\begin{small}
\iffalse %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\fi %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}
  \frametitle{Outline}
  \tableofcontents[pausesections]
  % You might wish to add the option [pausesections]
\end{frame}

\section{The specialists setup}

\begin{frame}
\frametitle{The specialists setup}
\begin{itemize}
\item Up till now we assumed that each expert makes a prediction at each iteration.
\item Imagine that experts are \B{specialists}, they predict only some of the time.
\item Gives the designer a lot of flexibility.
\item Generalizes the switching experts setup.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The specialists game}
On each iteration \R{$t=1,2,3,\ldots$}
\begin{itemize}
\item Adversary chooses a set \R{$E^t \subseteq \{1,\ldots,N\}$} of \B{awake} specialists.
\item Adversary chooses predictions for specialists in \R{$E^t$}
\item Algorithm chooses it's prediction.
\item Adversary chooses outcome.
\item Algorithm suffers loss. Specialists in \R{$E^t$} suffer loss. Sleeping specialists suffer no loss.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Desired bound}
\begin{itemize}
\item Algorithm has to predict on each iteration
\item Each specialist might sleep some of the time.
\item \R{$\Rightarrow$} makes no sense to compare to total loss of best specialist.
\item \R{$\vu$}: comparator distribution, 
\R{$u_i \geq 0,\;\; \sum_i u_i =1 $}.
\item Average loss w.r.t. \R{$\vu$}:
\R{$ \ell_{\vu}^t \doteq \frac{\sum_{i \in E^t} u_i \ell_i^t}{\sum_{i \in E^t} u_i}
$}
\item \B{Goal:} 
\R{$L_A \leq \min_{\vu} \sum_{t=1}^T \ell_{\vu}^t + \text{something small}$}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Ideas}
\begin{itemize}
\item We focus on \B{normalized} weights: 
\R{$$v_i^t = \frac{\wt{t}{i}}{\sum_{j=1}^N \wt{t}{i}},\;\;
 \vv^t = \frac{\wtvec{t}}{W^t}$$}
\item \B{Algorithm}: treat the set \R{$E_t$} as the set of experts.
\item \B{Normalize} the weights of specialists in \R{$E_t$} so that
\R{\[
\sum_{i\in E^t} v_i^t = \sum_{i\in E^t} v_i^{t+1}
\]}
\item
In particular: total weight is always \R{1}.
\end{itemize}
\end{frame} 

\begin{frame}
\frametitle{The log-loss case}
\begin{itemize}
\item \R{$x_{t,i}$} prediction of expert \R{$i$} on iteration \R{$t$}
\item \R{$\hat{y}_t$} prediction of algorithm.
\item \R{$y_t$} outcome at iteration \R{$t$} (0 or 1) 
\item 
\R{$$\ell_A^t = L(\hat{y}_t,y_t) =
  \begin{cases}
    -\ln \hat{y}_t & \mbox{ if } y_t=1\\
    -\ln (1-\hat{y}_t) & \mbox{ if } y_t=0
  \end{cases}
  $$}
\item \R{$\ell_i^t$} defined similarly for expert \R{$i$}
\end{itemize}
\end{frame}

% Define a color for mathematical expressions
%\newcommand{\redmath}[1]{\textcolor{red}{#1}}

\begin{frame}{Algorithm Bayes}
%\textbf{Parameters:} Prior distribution $\redmath{p_1 \in \Delta_N}$; number of trials $\redmath{T}$.

  Iterate for $\redmath{t = 1, 2, \dots, T}$
  \pause
\begin{enumerate}
    \item Predict with the weighted average of the experts' predictions:
          \[
          \redmath{\hat{y}_t = \sum_{i=1}^{N} p_{t,i} x_{t,i}}
          \]
    \item Observe outcome $\redmath{y_t}$.
    \item Update the posterior distribution:
          \[
            \redmath{p_{t+1,i} = 
            \begin{cases}
              \frac{p_{t,i} x_{t,i}}{\hat{y}_t} & \mbox{ if } y_t=1\\
              \frac{p_{t,i} (1-x_{t,i})}{1-\hat{y}_t} & \mbox{ if } y_t=0
            \end{cases}}
        \]
        
\end{enumerate}
\end{frame}

\begin{frame}{Algorithm SBayes}
%\textbf{Parameters:} Prior distribution $\redmath{p_1 \in \Delta_N}$; number of trials $\redmath{T}$.

  Iterate for $\redmath{t = 1, 2, \dots, T}$
  \pause
\begin{enumerate}
    \item Predict with the weighted average of the predictions of the awake specialists:
          \[ \redmath{
            \hat{y}_t = \frac{\sum_{i \in E_t} p_{t,i} x_{t,i}}
            {\sum_{i \in E_t} p_{t,i}}}
          \]
          where $\redmath{E_t}$ is the set of awake specialists.
    \item Observe outcome $\redmath{y_t}$.
\item Update the posterior distribution:
          \[\mbox{ if } i \in E_t: \;\;\;
            \redmath{p_{t+1,i} =
                          \begin{cases}
              \frac{p_{t,i} x_{t,i}}{\hat{y}_t} & \mbox{ if } y_t=1\\
              \frac{p_{t,i} (1-x_{t,i})}{1-\hat{y}_t} & \mbox{ if } y_t=0
            \end{cases}}
          \]
          \[\mbox{ if } i \notin E_t: \;\;\;
            \redmath{p_{t+1,i} =   p_{t,i}}
          \]
\end{enumerate}

\end{frame}

\begin{frame}{Bound for SBayes}
\begin{itemize}
\item
  For any sequence of awake specialists \R{$E_1,\ldots,E_T$}, specialist predictions and outcomes, and for any comparator $\vu$:
\R{$$
\sum_{t=1} u(E^t) \ell_A^t \leq \sum_{t=1}^T \sum_{i \in E^t} u_i \ell_i^t + \RE{\vu}{\vv^1}
$$}
\item \R{$ \RE{\vu}{\vv} \doteq \sum_i u_i \log \frac{u_i}{v_i}$}
\item \R{$ u(E^t) \doteq \sum_{i\in E^t} u_i $}
\item If we assume that \R{$u(E^t) = U$} is constant, we get
\R{\[
L_A \leq \sum_{t=1}^T \ell_{\vu}^t + \frac{\RE{\vu}{\vv^1}}{U}
\]} 
\end{itemize}
\end{frame}

\section{bounding cumulative loss using relative entropy}

\begin{frame}
  \frametitle{Proof of Bound (1)}
  Lemma:
  \R{\[
      \RE{\vu}{p_t} - \RE{\vu}{p_{t+1}}
      = u(E_t)L(\hat{y}_t,y_t) - \sum_{i \in E_t} u_i L(x_{t,i},y_t)
    \]}
  \pause
  From definition of \R{$\RE{}{}$}:
  \R{\[
      \RE{\vu}{p_t} - \RE{\vu}{p_{t+1}}
      = \sum_{i \in E_t} u_i \ln \frac{p_{t+1,i}}{p_{t,i}}
    \]}
  \pause
  If \R{$y_t=1$} the RHS is equal to
  \R{\begin{eqnarray*}
       \sum_{i \in E_t}u_i \ln \frac{x_{t,i}}{\hat{y}_t}
       &=& \sum_{i \in E_t}u_i \ln x_{t,i} -u(E_t) \ln \hat{y_t}\\
       &=& -\sum_{i \in E_t}u_i L(X_{t,i},y_t) + u(E_t) L(\hat{y}_t,y_t)
    \end{eqnarray*}}
  \pause
  Similarly for \R{$y_t=0$}
\end{frame}

\begin{frame}
\frametitle{Visual intuition}

\R{$
\RE{\vu}{\vv^{t}} - \RE{\vu}{\vv^{t+1}} = \ell_A^t - \vu \cdot \boldell^t
$}
\pause \\
\includegraphics[height=5cm,width=10cm]{figures/divergenceAnalysis.pdf}
\pause \\
\R{$\vv^{t+1}$} is chosen to minimize \R{$\RE{\vv^{t+1}}{\vv^t}+\vv^{t+1} \cdot \boldell^t$}

\end{frame}


\begin{frame}
  \frametitle{Proof of Bound (2)}
  Summing over \R{$t=1,\ldots,T$}:
  \R{\[
      \RE{\vu}{p_t} - \RE{\vu}{p_{t+1}}
      = u(E_t)L(\hat{y}_t,y_t) - \sum_{i \in E_t} u_i L(x_{t,i},y_t)
    \]}
  \pause
  We get
  \R{\begin{eqnarray*}
      \RE{\vu}{p_1} &\geq& \RE{\vu}{p_1} - \RE{\vu}{p_{T+1}}\\ &=&
      \sum_{t=1}^T u(E_t)L(\hat{y}_t,y_t) - \sum_{t=1}^T \sum_{i \in E_t} u_i L(x_{t,i},y_t)
    \end{eqnarray*}}

\end{frame}

\iffalse
\begin{frame}
\frametitle{Cumulative loss vs. Final total weight}

\onslide<1-> Total weight: \R{$W^t \doteq \sum_{i=1}^N \wt{t}{i}$}

\onslide<2-> \R{$$
\frac{W^{t+1}}{W^t}  =  \frac{\sum_{i=1}^N \wt{t}{i} e^{\log p_i^t(c^t)}}{\sum_{i=1}^N \wt{t}{i}} 
\onslide<3->          =   \frac{\sum_{i=1}^N \wt{t}{i} p_i^t(c^t)}{\sum_{i=1}^N \wt{t}{i}} 
\onslide<4->        =  p_A^t(c^t)
$$}
\onslide<5-> \R{$$ -\log \frac{W^{t+1}}{W^t} = -\log p_A^t(c^t) $$}
\R{\[
\onslide<8-> -\log W^{T+1} =
\onslide<6-> -\log \frac{W^{T+1}}{W^1} = -\sum_{t=1}^T \log p_A^t(c^t)
\onslide<7-> = L_A^T
\]}
%%\onslide<9-> \R{\bf EQUALITY} not bound!
\end{frame}


\begin{frame}
\frametitle{Relative Entropy}
\begin{itemize}
\item \R{$\vu,\vv$}: probability distributions, 
\R{$u_i \geq 0,\;\; \sum_i u_i =1 $}.
\item \R{$$ \RE{\vu}{\vv} \doteq \sum_i u_i \log \frac{u_i}{v_i}$$}
\item \R{$\RE{\vu}{\vv} \geq 0$}, \R{$\RE{\vu}{\vv} = 0$} iff 
\R{$\vu  = \vv$}
\item \R{$\exists \vu,\vv,\;\; \RE{\vu}{\vv} \neq \RE{\vv}{\vu}$}
\item \R{$\exists \vu_1,\vu_2,\vu_3,\;\; \RE{\vu_1}{\vu_3} >
  \RE{\vu_1}{\vu_2} + \RE{\vu_2}{\vu_3}$}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Normalized weights notation}

\begin{itemize}
\item \R{$p_i^t$}: distribution (of letters) predicted by expert \R{$i$} at time \R{$t$} 
\item Experts losses at time \R{$t$}:
\R{$\boldell^t = \left\langle \ell_1^t,\ldots,\ell_N^t \right\rangle 
                = - \left\langle \log p_1^t(c^t),\ldots,\log p_N^t(c^t)
		\right\rangle $}
\item Prediction of algorithm: \R{$p_A^t = \sum_{i=1}^N v_i^t p_i^t$}
\item Loss of algorithm at time \R{$t$}: \R{$\ell_A^t = -\log p_A^t(c^t)$} 
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Bounding cumulative log loss using relative entropy}

\begin{itemize}
\item Let \R{$\vu$} be an \B{arbitrary} distribution vector over experts.
\item \B{Lemma:}
\R{$
\RE{\vu}{\vv^{t}} - \RE{\vu}{\vv^{t+1}} = \ell_A^t - \vu \cdot \boldell^t
$}
\item Summing over \R{$t=1,\ldots,T$} we get:
\R{$
\RE{\vu}{\vv^{1}} - \RE{\vu}{\vv^{T+1}} = L_A - \vu \cdot \sum_{t=1}^T \boldell^t
$}
\item
\R{$ L_A \leq \min_{\vu} \paren{\vu \cdot \sum_{t=1}^T \boldell^t + \RE{\vu}{\vv^{1}}}$}
\item For the special case \R{$\vu = \langle 0,\ldots,0,1,0,\ldots,0
  \rangle$} and \R{$\vv^1 = \langle 1/N,\ldots,1/N \rangle$} we get
  the old bound:
\R{$ L_A \leq \min_i L_i + \log N $}
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Proof of Lemma}
\begin{itemize}
\item \R{$
\RE{\vu}{\vv^{t}} - \RE{\vu}{\vv^{t+1}} = \ell_A^t - \vu \cdot \boldell^t
$}
\item
\R{\begin{eqnarray*}
\lefteqn{\RE{\vu}{\vv^{t}} - \RE{\vu}{\vv^{t+1}}} \pause \\ 
& = & \sum_i u_i \log \frac{u_i}{v_i^t} - \sum_i u_i \log \frac{u_i}{v_i^{t+1}} \pause 
 =  \sum_i u_i \log \frac{v_i^{t+1}}{v_i^t} \pause \\
& = & \sum_i u_i \log \paren{\frac{W^t}{W^{t+1}} \; \frac{\wt{t+1}{i}}{\wt{t}{i}} } \pause \\
& = & \log \frac{W^t}{W^{t+1}} + \sum_i u_i \log e^{-\ell_i^t} \pause 
 =  \ell_A^T - \sum_i u_i \ell_i^t
\end{eqnarray*}}
\end{itemize}
\end{frame}
\fi

\iffalse
\begin{frame}
\frametitle{Using relative entropy to to express the bound}

\begin{itemize}
\item Relative Entropy:
\R{\[
\RE{\vu}{\vv}
\]}
\item Normalized weights 
\R{$v_i^t = \frac{w_i^t}{\sum_j w_j^t}$}
\item
\R{\[
\forall \vu \RE{\vu}{\vp^{t+1}} - \RE{\vu}{\vp^t} =
\ell_A^t - \vu \cdot \loss
\]}
\item For general \R{$(a,c)$}-achievable loss:
\R{\[
\forall \vu, \;\; \RE{\vu}{\vp^{t+1}} - \RE{\vu}{\vp^t}  \geq
(1/c) \ell_A^t - (a/c) \vu \cdot \boldell^t = 
\eta \ell_A^t - a \eta \vu \cdot \boldell^t
\]}
\end{itemize}
\end{frame}
\fi

\begin{frame}
\frametitle{bounding general loss using relative entropy}

\begin{itemize}
\item Suppose that loss is \R{$(a,c)$}-achievable. 
\item Achievable with Vovk algorithm, learning rate \R{$\eta=\frac{a}{c}$}
\item Let \R{$\vu$} be an \B{arbitrary} distribution vector over experts.
\item \B{Lemma}:
\R{$
\RE{\vu}{\vv^{t}} - \RE{\vu}{\vv^{t+1}} \geq \frac{1}{c} \ell_A^t - \frac{a}{c} \vu \cdot \boldell^t
$}
\item Summing over \R{$t=1,\ldots,T$} we get:
\R{$
\RE{\vu}{\vv^{1}} - \RE{\vu}{\vv^{T+1}} = \frac{1}{c} L_A - \frac{a}{c} \vu \cdot \sum_{t=1}^T \boldell^t
$}
\item
\R{$ L_A \leq \min_{\vu} \paren{a \vu \cdot \sum_{t=1}^T \boldell^t + c \RE{\vu}{\vv^{1}}}$}
\item For any mixable loss, \R{$a=1$}, using \R{$\vu = \langle 0,\ldots,0,1,0,\ldots,0
  \rangle$} and \R{$\vv^1 = \langle 1/N,\ldots,1/N \rangle$} we get the old bound:
\R{$ L_A \leq \min_i L_i + c \log N $}
\end{itemize}
\end{frame}

\section{Applications of specialists}

\begin{frame}
\frametitle{Example 1 Pruning trees}
\begin{itemize}
\item Consider the context algorithm.
  \item Each pruning is a generalist.
\item Each node is a specialist.
\item Gives an inferior algorithm (regret bound is twice as large as Context alg
  \item But much easier to generalize.
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example 2: Switching Experts}
  \begin{itemize}
  \item Consider the fixed share switching algorithm
  \item Each sequence of $d$ switches between base expert = generalist.
  \item Specialist for each base expert - sleeps unless active.
  \item gives the same algorithm.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Example 3: Routing}
  \begin{itemize}
  \item Consider a communication network defined by a DAG.
  \item goal: send packets from source to sink with minimal delay.
  \item protocol: after route is selected, delay is known.
  \item This is a multiple arm problem.
  \item Generalist: a possible route.
  \item Specialist: The choice of next hop for an individual router.
  \item Number of generalist is exponential in the number of specialists.
  \item Is it possible to achieve, using specialists?
    \item I don't know, could not find in the literature.
  \end{itemize}
\end{frame}


\iffalse %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Generic Example}
\begin{itemize}
\item Partition the input space. Assign each part to a specialist.
\item Use several partitions, of different fineness.
\item Can partition time in addition to space.
\item Parts do not have to be disjoint.
\item Partitions can adapt to data.
\item Your idea here...
\end{itemize}

\end{frame}
\begin{frame}
\frametitle{XXX}
\begin{itemize}
\item XXX
\end{itemize}
\end{frame}

\fi %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{small}
\end{document}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
