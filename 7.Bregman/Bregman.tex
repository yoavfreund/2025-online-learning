%\documentclass{beamer}
\documentclass[handout]{beamer}
% This file is a solution template for:

% - Giving a talk on some subject.
% - The talk is between 15min and 45min long.
% - Style is ornate.

% Copyright 2004 by Till Tantau <tantau@users.sourceforge.net>.
%
% In principle, this file can be redistributed and/or modified under
% the terms of the GNU Public License, version 2.
%
% However, this file is supposed to be a template to be modified
% for your own needs. For this reason, if you use this file as a
% template and not specifically distribute it as part of a another
% package/program, I grant the extra permission to freely copy and
% modify this file as you see fit and even to delete this copyright
% notice. 


\mode<presentation>
{
  \usetheme{Montpellier}

  %\setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}

\usepackage{xmpmulti} % package that defines \multiinclude

\usepackage[english]{babel}

\usepackage[latin1]{inputenc}

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\title[\ouralg] % (optional, use only with long paper titles)
{Online learning using Bregman Divergences}

\author[Freund] % (optional, use only with lots of authors)
{Yoav Freund}
% - Give the names in the same order as the appear in the paper.
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[Universities of Somewhere and Elsewhere] % (optional, but mostly needed)

\subject{Machine Learning}
% This is only inserted into the PDF information catalog. Can be left
% out. 

% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
%% \AtBeginSubsection[]
%% {
%%   \begin{frame}<beamer>
%%     \frametitle{Outline}
%%     \tableofcontents[currentsection,currentsubsection]
%%   \end{frame}
%% }


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

\beamerdefaultoverlayspecification{<+->}

% \newcommand{\R}[1]{{\color{red}{#1}}}
% \newcommand{\W}{\vec{W}}
% \newcommand{\V}{\vec{V}}
% \newcommand{\X}{\vec{X}}
% \newcommand{\loss}{\vec{\ell}}
% \newcommand{\HedgeLoss}{L_{\mbox{\footnotesize Hedge}}}

\input{../macros}

\begin{document}

%\iffalse %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\fi %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
  \titlepage
  \begin{small}
  \end{small}
\end{frame}

\begin{frame}
  \frametitle{Outline}
  \tableofcontents[pausesections]
  % You might wish to add the option [pausesections]
\end{frame}


\section{\ouralg Algorithm}

\begin{frame}
\frametitle{The hedging problem}

\begin{itemize}
\item \R{$N$} possible actions 

\item At each time step \R{$t=1,2,\ldots,T$}:
\begin{itemize}
\item Algorithm chooses a distribution \R{$\distvec{t}$} over actions.
\item Losses \R{$0 \leq \cost{t}{i} \leq 1$} of all actions \R{$i=1,\ldots,N$} are revealed.
\item Algorithm suffers {\bf expected} loss \R{$\distvec{t} \cdot \costvec{t}$}
\end{itemize}
\item {{\bf Goal:} minimize total expected loss}
\item {Here we have stochasticity - but only in {\bf algorithm}, not in {\bf outcome}}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The \ouralg Algorithm}
~\\
Consider action \R{$i$} at time \R{$t$}
\begin{itemize}
\item Total loss:
\R{$$L_i^t = \sum_{s=1}^{t-1} \ell_i^s$$}
\item Weight:
\R{$$\wt{t}{i} = \wt{1}{i} e^{-\eta L_i^t}$$}
Note freedom to choose initial weight (\R{$\wt{1}{i}$})
\R{$\sum_{i=1}^n \wt{1}{i} = 1$}.
\item
\R{$\eta>0$} is the learning rate parameter. Halving: \R{$\eta \to \infty$}

\item Probability:
\R{$$\dist{t}{i} = \frac{\wt{t}{i}}{\sum_{j=1}^N \wt{t}{i}},\;\;
  \pause     \distvec{t} = \frac{\wtvec{t}}{\sum_{j=1}^N \wt{t}{i}}$$}
\end{itemize}
\end{frame}

\section{Bound on total loss}
\begin{frame}
\frametitle{Bound on the loss of \ouralg Algorithm}
\begin{itemize}
\item
\begin{theorem}[main theorem] \label{thm:basic-bnd}
For any sequence of loss vectors \R{$\costvec{1},\ldots,\costvec{\iter}$},
and for any \R{$i\in\{1,\ldots,N\}$}, we have
\R{\begin{equation*}
\lossouralg \leq \frac{-\ln(\wt{1}{i}) + \eta \lossi{i}}
		      {1-e^{-\eta}}.
\end{equation*}}
%% More generally, for any nonempty set $S\subseteq\{1,\ldots,N\}$, we have
%% \begin{equation}\label{eqn:set-bnd}
%% \lossouralg \leq \frac{-\ln(\sum_{i\in S}\wt{1}{i})
%% 			 - \eta \max_{i\in S} \lossi{i}}
%% 		      {1-e^{-eta}}.
%% \end{equation}
\end{theorem}
\item
\R{Proof}: by combining upper and lower bounds on \R{$\sumwts{\iter+1}$}
\end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Comparing with the best distribution}
  \begin{itemize}
  \item {\bf Comparison class:} single experts.
    hindsite.
  \item Does not take advantage of multiple good experts.
  \item We will get tighter bounds by increasing the comparison class
    to include all {\bf convex combinations} of the experts.
  \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Recall Single step bound for \ouralg}
The total weight has to decrease if the loss is large
\R{\[
\sumwts{t+1} \leq  \paren{\sumwts{t}} \left( 1-(1-e^{-\eta}) \distvec{t}\cdot\costvec{t} \right)
\]}
\end{frame}

\begin{frame}
  \frametitle{Enlarging the comparison set}
  \begin{itemize}
  \item Bound compares cumulative loss to that of best expert in
    hindsite.
  \item Does not take advantage of multiple good experts.
  \item We will get tighter bounds by comparing to the best convex
    combination of experts.
  \end{itemize}
\end{frame}


\newcommand{\vecq}{\bdistvec{}}
\begin{frame}
  \frametitle{Comparing with the best distribution}
  \begin{itemize}
  \item Denote by \R{$\vecq$} an arbitrary distribution over \R{$N$}
    experts. \R{$\vecq \in \Delta^N$}. Distribution = convex combination.
  \item Compare loss of algorithm to loss of best
    convex combination of experts:
  \R{\[ \sum_{t=1}^T L_A^t \leq + a \min_{\vecq \in
        \Delta^N} \sum_{t=1}^T \vecq \cdot \costvec{t} + c X \]}
  \item When comparing to single best expert \R{$X=\log N$}
  \item \B{\bf Intuition:} \R{$X$} should be small if best distribution
    \R{$\vecq^*$} is \B{close} to initial distribution \R{$\distvec{0}$}
  \end{itemize}
\end{frame}

  \begin{frame}
    \frametitle{Relative Entropy Bound}
    \begin{itemize}
  \item KL-divergence or Relative Entropy:
    \R{X}
  \item For any distribution \R{$\vecq$} and any iteration of
    $\ouralg$:
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{Proof (from RE to ratio)}
\end{frame}

\begin{frame}
\frametitle{Proof (from ratio to bound)}
\end{frame}

\begin{frame}
\frametitle{Visual Intuition}
\end{frame}


\end{document}


